<html>
<head>

<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
<link href='http://fonts.googleapis.com/css?family=Lato:300,400,900' rel='stylesheet' type='text/css'>
<link href="style.css" rel="stylesheet">
<title>Efficient bandwidth extension of musical signals
using a differentiable harmonic plus noise model</title>
</head>
<body>

    <div id="header" class="container-fluid">
            <h1>Diffusion-based Spectral Super-Resolution of <br>Third Octave Acoustic Sensor Data: Is Privacy at Risk ?</h1>
   </div>


<div class="authors">
	Modan Tailleur, Chaymae Benaatia, Mathieu Lagrange, Pierre Aumond, Vincent Tourre
</div>
<div class="authors">
	Contact: modan.tailleur@ls2n.fr
</div>
<div class="container">
    <h2>Abstract</h2>
    <p>

        Third octave spectral recording of Acoustic sensor data is an effective way of measuring the environment. While there is strong evidence that slow (1s frame, 1 Hz rate) and fast (125ms frame, 8Hz rate) versions lead by-design to unintelligible speech if reconstructed, the advent of high quality reconstruction methods based on diffusion may pose a threat, as those approaches can embed a significant amount of <i>a priori</i> knowledge when learned over extensive speech datasets. 

        This paper aims to assess this risk at three levels of attacks with a growing level  of <i>a priori</i> knowledge considered at the learning of the diffusion model, a) none, b) multi-speaker data excluding the target speaker and c) target speaker. Without any prior regarding the speech profile of the speaker (levels a and b), our results suggest a rather low risk as the word-error-rate both for humans and automatic recognition remains higher than 89%.


    </p>
    <p>This is the companion page for the paper: TBF</p>
    <p>Please, cite as: TBF</p>
    <p>Experience code is available in <a href="https://github.com/modantailleur/paperThirdOctavePrivacy">this github repository</a>.</p>
</div>

<div class="container" id="table_techniques">
  <h2>Voice reconstruction from Fast Third-Octave</h2>
  <p>Bellow, the voice extracts generated from the different methods on LJ002-0068.wav audio from the LJSpeech test set.</p>
  <table class="table table-responsive">
      <thead>
        <tr class="text-center">
          <td rowspan="2"></td>
          <td rowspan="2"></td>
          <td colspan="2" style="border-left: 1px solid rgb(185, 185, 185);">AL0</td>
          <td style="border-left: 1px solid rgb(185, 185, 185);">AL1</td>
          <td colspan="1" style="border-left: 1px solid rgb(185, 185, 185);">AL2</td>
          <td rowspan="2" style="border-left: 1px solid rgb(185, 185, 185);">Reference</td>
      </tr>
      <tr class="text-center">
          <td style="border-left: 1px solid rgb(185, 185, 185);">PINV</td>
          <td >Diffspec</td>
          <td style="border-left: 1px solid rgb(185, 185, 185);">Diffspec</td>
          <!-- <td style="border-left: 1px solid rgb(185, 185, 185);">Diffwave</td> -->
          <td style="border-left: 1px solid rgb(185, 185, 185);">Diffspec</td>
      </tr>
      </thead>
      <tbody>
        <tr>
          <td class="desc">LJ002-0068</td>
          <td class="desc">LJSpeech</td>
          <td class="text-center" style="border-left: 1px solid rgb(185, 185, 185);">
              <audio controls class="sample_audio">
                  <source src="audio/for_companion_page/evalset=ljspeech+method=pinv+step=vocode+tho_type=fast___gomin___LJ003-0180.wav" type="audio/wav">
              </audio>
          </td>
          <td class="text-center">
              <audio controls class="sample_audio">
                  <source src="audio/for_companion_page/dataset=tau+diff_steps=1000+epoch=40+evalset=ljspeech+learning_rate=-4+method=diffusion+schedule=DDPM+seed=71+step=vocode+tho_type=fast___gomin___LJ003-0180.wav" type="audio/wav">
              </audio>
          </td>
          <td class="text-center" style="border-left: 1px solid rgb(185, 185, 185);">
              <audio controls class="sample_audio">
                  <source src="audio/for_companion_page/dataset=librispeech+diff_steps=1000+epoch=40+evalset=ljspeech+learning_rate=-4+method=diffusion+schedule=DDPM+seed=71+step=vocode+tho_type=fast___gomin___LJ003-0180.wav" type="audio/wav">
              </audio>
          </td>
          <!-- <td class="text-center" style="border-left: 1px solid rgb(185, 185, 185);">
              <audio controls class="sample_audio">
                  <source src="audio/for_companion_page/dataset=ljspeech+diff_steps=1000+epoch=70+evalset=ljspeech+learning_rate=-4+method=diffwave+schedule=DDPM+seed=71+step=vocode+tho_type=fast___LJ003-0180.wav" type="audio/wav">
              </audio>
          </td> -->
          <td class="text-center" style="border-left: 1px solid rgb(185, 185, 185);">
              <audio controls class="sample_audio">
                  <source src="audio/for_companion_page/dataset=ljspeech+diff_steps=1000+epoch=70+evalset=ljspeech+learning_rate=-4+method=diffusion+schedule=DDPM+seed=71+step=vocode+tho_type=fast___gomin___LJ003-0180.wav" type="audio/wav">
              </audio>
          </td>
          <td class="text-center" style="border-left: 1px solid rgb(185, 185, 185);">
              <audio controls class="sample_audio">
                  <source src="audio/for_companion_page/LJ003-0180.wav" type="audio/wav">
              </audio>
          </td>
      </tr>
      <tr>
          <td class="desc">8463-294828-0003.flac</td>
          <td class="desc">Librispeech</td>
          <td class="text-center" style="border-left: 1px solid rgb(185, 185, 185);">
              <audio controls class="sample_audio">
                  <source src="audio/for_companion_page/evalset=librispeech+method=pinv+step=vocode+tho_type=fast___gomin___8463-294828-0003.wav" type="audio/wav">
              </audio>
          </td>
          <td class="text-center">
              <audio controls class="sample_audio">
                  <source src="audio/for_companion_page/dataset=tau+diff_steps=1000+epoch=40+evalset=librispeech+learning_rate=-4+method=diffusion+schedule=DDPM+seed=71+step=vocode+tho_type=fast___gomin___8463-294828-0003.wav" type="audio/wav">
              </audio>
          </td>
          <td class="text-center" style="border-left: 1px solid rgb(185, 185, 185);">
              <audio controls class="sample_audio">
                  <source src="audio/for_companion_page/dataset=librispeech+diff_steps=1000+epoch=40+evalset=librispeech+learning_rate=-4+method=diffusion+schedule=DDPM+seed=71+step=vocode+tho_type=fast___gomin___8463-294828-0003.wav" type="audio/wav">
              </audio>
          </td>
          <!-- <td class="text-center" style="border-left: 1px solid rgb(185, 185, 185);">-</td> Replaced audio with a dash -->
          <td class="text-center" style="border-left: 1px solid rgb(185, 185, 185);">-</td> 
          <td class="text-center" style="border-left: 1px solid rgb(185, 185, 185);">
              <audio controls class="sample_audio">
                  <source src="audio/for_companion_page/8463-294828-0003.wav" type="audio/wav">
              </audio>
          </td>
      </tr>
      </tbody>
    </table>
    <p>Here is the Whisper "large-v3" transcription using the PINV algorithm for the LJ002-0068.wav audio: <br>
        <i>"These words were always supposed to go on the floor. Sometimes they all went on for a boon or a comedy or a family or a friend."</i>
    </p>
    <p>And for the 8463-294828-0003.flac audio:<br>
        <i>"I'll be back in Hawaii to see my country again. I'm a friend. I'm not a scorer by the temple gardens. I really love relations."</i>
    </p>
    <p>Although most of the words are incorrect, it is notable 
    that some are still accurately transcribed, despite the PINV audios being perceptually unintelligible.
    Whisper "large-v3" model was thus removed from the discussions, as this behavior may result from overfitting 
    due to the use of LJSpeech and LibriSpeech audio in training the Whisper models.</p>
</div>

<div class="container" id="table_effects">
  <h2>Influence of diffusion steps</h2>
  <p>Below are the voice extracts generated from training on the LJSpeech dataset either with 200 diffusion steps or 1000 diffusion steps, using the LJ002-0068.wav audio from the LJSpeech test set. We observe that with 200 diffusion steps, the audio quality remains similar; however, fewer words are intelligible, and the speech becomes slightly more disjointed. The training with 1000 diffusion steps is thus retained for the experiment.</p>
  <table class="table table-responsive">
    <thead>
      <tr class="text-center">
        <td rowspan="2"></td>
        <td rowspan="2"></td>
        <td colspan="2" style="border-left: 1px solid rgb(185, 185, 185);">Diffusion steps</td>
    </tr>
    <tr class="text-center">
        <td style="border-left: 1px solid rgb(185, 185, 185);">200</td>
        <td>1000</td>
    </tr>
    </thead>
    <tbody>
      <tr>
        <td class="desc">LJ002-0068</td>
        <td class="desc">LJSpeech</td>
        <td class="text-center" style="border-left: 1px solid rgb(185, 185, 185);">
            <audio controls class="sample_audio">
                <source src="audio/for_companion_page/dataset=ljspeech+diff_steps=200+epoch=70+evalset=ljspeech+learning_rate=-4+method=diffusion+schedule=DDPM+seed=71+step=vocode+tho_type=fast___gomin___LJ003-0180.wav" type="audio/wav">
            </audio>
        </td>
        <td class="text-center">
            <audio controls class="sample_audio">
                <source src="audio/for_companion_page/dataset=ljspeech+diff_steps=1000+epoch=70+evalset=ljspeech+learning_rate=-4+method=diffusion+schedule=DDPM+seed=71+step=vocode+tho_type=fast___gomin___LJ003-0180.wav" type="audio/wav">
            </audio>
        </td>
    </tr>
    </tbody>
  </table>

  
</div>

<div class="container" id="table_effects">
    <h2>Influence of the vocoder</h2>
    <p>Below are the voice extracts generated from training on the LJSpeech dataset, using either Griffin-Lim with 30 iterations as a vocoder or GomiGAN. While the intelligibility of the words is similar in both cases, the audio quality produced by GomiGAN is slightly better, and GomiGAN is 15 times faster when using a GPU:</p>
    <table class="table table-responsive">
      <thead>
        <tr class="text-center">
          <td rowspan="2"></td>
          <td rowspan="2"></td>
          <td colspan="2" style="border-left: 1px solid rgb(185, 185, 185);">Vocoder</td>
      </tr>
      <tr class="text-center">
          <td style="border-left: 1px solid rgb(185, 185, 185);">Griffin-Lim (30 iter)</td>
          <td>GomiGAN</td>
      </tr>
      </thead>
      <tbody>
        <tr>
          <td class="desc">LJ002-0068</td>
          <td class="desc">LJSpeech</td>
          <td class="text-center" style="border-left: 1px solid rgb(185, 185, 185);">
              <audio controls class="sample_audio">
                  <source src="audio/for_companion_page/dataset=ljspeech+diff_steps=1000+epoch=70+evalset=ljspeech+learning_rate=-4+method=diffusion+schedule=DDPM+seed=71+step=vocode+tho_type=fast___grifflim___LJ003-0180.wav" type="audio/wav">
              </audio>
          </td>
          <td class="text-center">
              <audio controls class="sample_audio">
                  <source src="audio/for_companion_page/dataset=ljspeech+diff_steps=1000+epoch=70+evalset=ljspeech+learning_rate=-4+method=diffusion+schedule=DDPM+seed=71+step=vocode+tho_type=fast___gomin___LJ003-0180.wav" type="audio/wav">
              </audio>
          </td>
      </tr>
      </tbody>
    </table>
  
    
  </div>

<script>
function setupCallback(elem, elems) {
  elem.addEventListener("play", function () {
    for (var other of elems) {
      if (other !== elem) {
        other.pause();
        // other.currentTime = 0.;
      }
    }
  });
}

document.addEventListener('DOMContentLoaded', function () {
  var elems = document.body.getElementsByTagName("audio");
  for (var elem of elems) {    setupCallback(elem, elems);
  }
});
</script>
</body>
</html>
